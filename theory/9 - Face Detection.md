# Face Detection

Il volto è una biometria al limite, in quanto essa è soggetta a cambiamenti temporali, ma allo stesso tempo è la biometrica con la quale si riconoscono le persone. La pareidolia è l’illusione subcosciente che tende a ricondurre a forme note, oggetti o profili (naturali o artificiali) dalla forma casuale. 

Il volto è largamente utilizzato come biometria, infatti i due più importanti fattori che sanciscono il successo di una biometria sono affidabilità e accettabilità. Il riconoscimento dell’iride è il sistema più affidabile, ma è anche quello più intrusivo. Le impronte digitali sono più facilmente accettate, ma non applicabili a soggetti non consenzienti. Il volto possiede un’accettabilità molto elevata, mentre l’affidabilità deve essere ancora migliorata. 

Ma il volto è una struttura tridimensionale piuttosto complessa che quando viene acquisita, soprattutto se viene acquisita da un solo punto di vista, diventa bidimensionale perdendo una parte delle informazioni. Questa sua complessità è il limite che si ottiene quando si effettua l’acquisizione da un solo punto di vista, essa determina una certa inaffidabilità legata ad un altro limite sostanziale del volto e cioè la sua eccessiva variabilità intra-classe, infatti essa introdotta all’interno di un sistema di riconoscimento bisogna immaginare un aggiornamento periodico del template.

Un altro aspetto fortemente perturbativo dei sistemi di Face Recognition sono le perturbazioni che possono essere indotte dall’acquisizione; il volto è una delle poche biometriche che può essere variata dall’individuo a differenza di altre, infatti si possono produrre delle variazioni volontarie sul volto (espressioni o smorfie). Quando a queste variazioni si aggiungono ulteriori fattori perturbativi come la variazione di posa e illuminazione, si creano le PIE variations (Pose, Illumination, Expression).

L’altro fattore che non è indotto dalla persona e dalle condizioni ambientali è il cosiddetto Ageing (A-PIE, PIE variations + Ageing), ovvero la variazione dell’età. 

Quando si sviluppa una tecnica di face Recognition, essa la si testa su database comuni per comprendere in modo comparativo, se l’idea algoritmica prodotta risulta essere migliore rispetto ad altre. Negli anni sono stati prodotti diversi database e quando la comunità scientifica produce un nuovo algoritmo, tende ad utilizzare uno più database per avere una misura comparativa con quello che è stato prodotto in precedenza.

## Approcci alla Face Detection

Il primo passo è legato ad individuare all’interno di un video/immagine la presenza di un volto. Una volta che il volto è stato individuato con qualche tecnica, allora è possibile darlo in input al sistema di classificazione che deve estrarre le caratteristiche principali. Il primo problema da risolvere, è quello di costruire un face detector efficace, ovvero come capire se in un’immagine vi è un volto. 

La tecniche per effettuare operazioni di Face Detection sono diverse. Le più elementari ma comunque estremamente performanti sono quelle basate su caratteristiche di basso livello che possono riguardare alcune caratteristiche dei pixel (luminosità del volto o geometria del volto). Infatti, tutti i punti che individuano occhi, narici, sopracciglia ecc… creano una costellazione di informazioni che possono essere legate da una serie di relazioni geometriche. Oppure si può immaginare di avere un template di un volto rappresentabile con un modello matematico. Tutte queste sono caratteristiche di basso livello nelle quali si possono individuare le tecniche di face detection features-based; esse sono tecniche che sfruttano alcune proprietà di basso livello del volto per individuarlo all’intero di una immagine.

Poi ci sono degli approcci che piuttosto che basarsi sulle caratteristiche elementari del volto sfruttano le immagini nella loro totalità, le cosiddette tecniche imaged-based. Queste tecniche si basano sull’addestramento di modelli computazionali, in grado di riconoscere determinati oggetti sulla base di un pre-addestramento effettuato. Si costruisce un dataset di addestramento, dove all’interno ci sono sia immagini contenenti volti e sia immagini non contenenti volti, e si allena il sistema a riconoscere soltanto i volti.

Una delle tecniche basate sulle caratteristiche di basso livello sfrutta la relazione tra il modello RGB e YCC. Quest’ultimo è quello più utilizzato nell’image processing; è un modello nel quale è possibile separare un componente dell’immagine, rispetto a delle altre, concentrando in questa componente (Y) la maggior parte dell’informazione significativa. La transizione tra i due modelli avviene attraverso una trasformazione lineare che mappa il modello RGB nel modello YCC. Nel caso del modello YCC l’informazione che interessa non è contenuta nella componente di luminanza Y, ma piuttosto nelle altre due componenti C C (crominanza). Nella componente di crominanza sono particolarmente evidente alcune caratteristiche del volto, in particolare occhi e bocca; presa questa componente di crominanza si applicano una serie di operatori (equalizzazione e AND) che tendono a massimizzare gli aspetti che interessano occhi e bocca. La loro individuazione permette di avere una certa probabilità che l’immagine in considerazione contenga un volto. Tale tecnica produce molti falsi positivi (volti dove non ci sono).

Un approccio che rientra più nell’ambito geometrico prevede l’individuazione della bocca e degli occhi ma vincola essi ad una certa relazione geometrica. Ovvero deve crearsi un triangolo che gode di alcune proprietà specifiche. Tale triangolo viene anche legato ad esser circoscritto da una circonferenza che rappresenta il volto vero e proprio. Si passa ad un approccio di natura geometrica in quanto ci si basa non solo sulla presenza di occhi e bocca ma anche sulle caratteristiche geometriche che vengono calcolate sulla base di una serie di operatori.

## Viola-Jones e Integral Images

Paul Viola e Michael Jones hanno proposto uno degli approcci di maggior successo (finora) alla localizzazione degli oggetti (incluso in OpenCV). L'algoritmo è image-based e può essere applicato al rilevamento del volto (ma anche al rilevamento di occhi e bocca in una strategia gerarchica). Esso richiede di creare un classificatore inizialmente addestrato utilizzando più istanze della classe da identificare (esempi positivi), e diverse istanze di immagini che non contengono alcun oggetto della classe ma che possono causare un errore (esempi negativi). Il Training è progettato per estrarre diverse funzionalità dagli esempi e per selezionare quelle più discriminanti. 

Il modello statistico che viene costruito in modo incrementale contiene tali informazioni. Misses(un oggetto presente non viene rilevato) o False Alarms(un oggetto viene rilevato ma non è presente) possono essere ridotti riqualificando l'aggiunta di nuovi esempi adatti (positivi o negativi). L’algoritmo di Viola-Jones è un algoritmo composito in cui ci sono alcuni aspetti che di fatto mettono insieme un po' tutto quello che è stato analizzato in precedenza nell’ambito dell’elaborazione delle immagini. È un algoritmo molto veloce in quanto vengono posti in modo preliminare al processo di riconoscimento vero e proprio, utilizzando dei classificatori, dei filtri e attraverso la combinazione di essi, mette a punto una strategia gerarchica affinché riesca ad individuare se in un’immagine è presente un volto. 

L’algoritmo di Viola-Jones sfrutta le cosiddette caratteristiche di Haar, cioè delle caratteristiche tipiche del volto, condivise da tutti i volti umani. Queste caratteristiche presenti nel volto vengono rappresentate da dei filtri che vengono sovrapposti all’immagine. Tali filtri cercano di verificare la presenza di alcuni aspetti tipici del volto umano, come ad esempio la regione perioculare (occhi) è generalmente più scura della zona sottostante (zigomi) cosi come il ponte del naso è normalmente più luminoso degli occhi. Tendenzialmente si possono utilizzare filtri molti simili a questi per cercare di capire se all’interno di una immagine c’è un’alternanza di regione scura/chiara, perché tale alternanza potrebbe essere sintomo di presenza di occhi e zigomi. Così come un’alternanza nero/bianco/nero potrebbe essere funzionale all’aver individuato occhio/ponte del naso/occhio. 

È chiaro che queste sono condizioni necessarie ma non sufficienti per individuare un volto, ed è chiaro che di questi filtri se ne dovranno considerare diversi da far passare sul volto al fine di poter avere una certezza che quel che viene isolato è effettivamente un volto. Una volta individuato il filtro da far scorrere sull’immagine lo si sovrappone su di essa e si verifica la variazione fra zona chiara e zona scura: si moltiplicano per 1 i pixel dell’area bianca e per 0 i pixel dell’area nera e si effettua una differenza, che poi viene controllata se essa supera una certa soglia; se si supera una certa soglia allora vuol dire che quel filtro ha una forte probabilità di aver localizzato una regione dell’immagine. Il valore di una determinata funzione è sempre semplicemente la somma dei pixel all'interno di rettangoli chiari sottratti dalla somma dei pixel all'interno rettangoli ombreggiati. Caratteristiche rettangolo: 

Valore = Σ (pixel nell'area nera) - Σ (pixel nell'area bianca). 

Tre tipi: due, tre, quattro rettangoli, Viola e Jones hanno utilizzato le funzioni a due rettangoli. Ad esempio: la differenza di luminosità tra i rettangoli bianchi e neri su un'area specifica. Ogni funzione è correlata a una speciale posizione nella finestra secondaria. 

Una serie di filtri vengono applicati sull’immagine: diversi filtri dove ognuno dovrebbe individuare una parte significativa dell’immagine. Quando viene individuata un’area potenzialmente assimilabile ad un’immagine il quadro si blocca in quanto si è in presenza del primo frame utilizzabile per classificare l’immagine come volto. I filtri possono avere diverse dimensioni e le finestre possono essere di diversa grandezza. 

Vengono mostrate alcune delle caratteristiche che possono essere utilizzate da Viola-Jones. Uno dei problemi di tale algoritmo è che dovrebbe unire efficacia ad efficienza, quindi bravo nell’evidenziare i potenziali volti in un tempo piuttosto rapido. Il problema è che ogniqualvolta viene applicata una mascherina come in figura sull’immagine, devono essere effettuate delle semplici operazioni (moltiplicazioni e sottrazioni) ripetute un gran numero di volte su tutta quanta l’immagine, in quanto tali operazioni vengono effettuate per ognuno dei filtri con dimensione anche variabile dei filtri stessi. Per ridurre il costo computazionale l’immagine viene trasformata nella cosiddetta Integral Image. 

L’algoritmo utilizza delle Haar features in combinazione con una nuova rappresentazione dell'immagine detta Integral Image. Le features hanno basso costo computazionale e la nuova struttura dati permette di effettuare l'analisi in tempo costante indipendentemente dalla dimensione delle regioni analizzate. Viene introdotto un metodo di selezione di feature di Haar attraverso l'algoritmo AdaBoost di Freud Shapire (1995). Questa strategia permette di eliminare in addestramento la maggior parte delle feature di scarsa capacità discriminante e selezionare solo quelle più efficaci per il problema. 

L’*immagine integrale* non è nient’altro che una rappresentazione/trasformazione più efficiente dell’immagine per realizzare queste moltiplicazioni e sottrazioni. Come in figura, l’immagine integrale viene costruita sommando i pixel in maniera progressiva. Quindi ogni pixel rappresenta la somma dei pixel precedenti in maniera crescente partendo da sinistra verso destra e dall’alto verso il basso. La rappresentazione dell’immagine in termini di immagine integrale permette di realizzare la somma dei pixel in una qualsiasi area (rettangolo o quadrato di riferimento) attraverso un numero più efficiente di operazioni, ovvero solamente tre operazioni. Indipendentemente dalla dimensione del filtro si potrà sempre realizzare la somma dei pixel all’interno di un’immagine in termini di: A - B - C + D facendo fondamentalmente solo tre operazioni elementari; questo risulta essere un grande vantaggio in quanto applicando un filtro di HAAR sull’immagine, si può avere in tempo constante (le sole tre operazioni) indipendentemente dal numero di pixel che sono coperti, la somma dei pixel. Poiché fondamentalmente nei filtri di HAAR si deve effettuare la somma dei pixel per poi fare la differenza, la riuscita di queste operazioni velocemente è un grande vantaggio. La scelta dei filtri e il peso assegnato viene fatto con dei classificatori Ada Boosting. 