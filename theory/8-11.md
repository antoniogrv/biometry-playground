# Occhio

L’occhio è una sfera avente un diametro di 20 millimetri formato dal nervo ottico e da diverse membrane concentriche quali:
- Cornea (trasparente)
- Sclera (opaca)
- Coroide (rete di vasi sanguigni)
  - Corpo Ciliare (agisce sul cristallino)
  - Iride (diaframma con un foro: pupilla che va dai 2 a 8 millimetri)
- Retina: è una varietà di celle e oltre 100 milioni di fotorecettori
   - Fovea: ha pochi bastoncelli, non ha vasi sanguigni, è densa di recettori dei coni.
      - Coni: sensibili ai colori ma insensibili alla luce, 100 fotoni per una risposta paragonabile ai bastoncelli (6 milioni - Photopic Vision)
      - Bastoncelli: sensibili alla luce, emettono risposta al singolo fotone (75/150 milioni - Scotopic Vision)

# Modelli di colore

L’occhio umano possiede uno spettro visibile, per avere un’idea della gamma di colori che l’occhio umano possa percepire, si fa riferimento alla luce bianca che attraversa un prisma ottico.La luce visibile in realtà non è nient’altro che una serie di onde elettromagnetiche nell’intervallo [380nm, 780nm]. 
- Ultravioletto <380 nm
- Infrarosso >780 nm

La percezione del colore avviene attraverso la combinazione di tre stimoli primari (tricromia): a livello della retina viene filtrato il segnale e diviso in tre colori: blu, rosso e verde (verde-giallo).

Il colore di un oggetto è percepito come luce riflessa dall’oggetto stesso. Un oggetto che riflette luce in modo omogeneo sull’intero spettro visibile è percepito di colore bianco. Un oggetto che assorbe luce in modo omogeneo sull’intero spettro visibile è percepito di colore nero. Il nostro occhio, a differenza dell’orecchio, non è in grado dieffettuare un’analisi spettrale, ma riporta una sensazione risultante dalla combinazione di tutte le lunghezze d’onda visibili. È inoltre impossibile comunicare la sensazione corrispondente ad un certo stimolo. Quello che possiamo comunicare è che due stimoli diversi producono la stessa sensazione.

## Classi di immagini a colori

- True colors (Colori Veri) è ottenuta mediante composizione (sottrattiva o additiva di tre componenti: HSB, RGB, CYM, YIQ). Ogni componente è quantizzata con un numero definito di bit.
- Pseudo-Colors (Colori Falsi) è ottenuta assegnando ad ogni intervallo di colori veri un colore medio.

- Il modello di colore RGB è utilizzato per realizzare dispositivi di proiezione quali monitors, TV e
nell’elaborazione di immagini. Viene utilizzato anche per immagini satellitari. Additivo: Si addiziona luce (RGB) al nero.
- Il modello di colore CYM è utilizzato per realizzare dispositivi di stampa. Sottrattivo: Si sottrae luce (CYM) al bianco
- Il modello di colore HSB (HSV) è utilizzato nell’Elaborazione di Immagini. Combinazione di Hue (Tonalità), Saturazione (Saturation), Luminosità (Brightness)
- Il modello di colore YIQ (YUV) è utilizzato nelle trasmissioni TV e nell’elaborazione di immagini. Sfrutta la maggiore sensibilità dell’occhio umano alla luminanza (immagini a livelli di grigio)

Il gamut è l’insieme dei colori che possono essere realizzati dalla combinazione di tre primari. Il modello 
LAB (L = Luminosità, a = asse verde-rosso, b = asse blu-giallo) copre tutti i colori nello spettro visibile.
Il gamut RGB è minore del LAB, quindi alcuni colori (giallo puro, ciano puro) non possono essere visualizzati 
sul monitor.
Il gamut CMYK è il più piccolo (ma non è un semplice sottoinsieme del gamut RGB). L’elenco dei colori disponibili è chiamato palette.



# Iride

Dal punto di vista anatomico, l’iride è un muscolo avente una funzione cromatica, che agisce sul foro presente al centro dell’occhio, ovvero la pupilla. Quest’ultima è il foro attraverso il quale entra la luce del sole, che va a impattarsi sula retina. I muscoli che agiscono attraverso movimenti “involontari” hanno il compito di comprimere e far dilatare la pupilla per consentire l’entrata di una certa quantità di luce. Inoltre, dal punto di vista scientifico le striature presenti sull’iride (pattern irregolari) caratterizzano la cromaticità dell’iride. È possibile individuare tra due consanguinei anche una stessa cromaticità dell’iride, ma ciò che viene diversificato sono appunto tali striature casuali (solchi e creste) che vanno a caratterizzare la parte cromatica. Quindi nell’iride si va a rilevare la distribuzione di tali pattern irregolari, piuttosto che la cromaticità del colore, infatti tali pattern rendono unica l’iride dal punto di vista dell’identificazione. Addirittura, l’iride destra è diversa da quella sinistra. L’iride si trova tra la cornea e il cristallino. 

- *Vantaggi*: l’iride è ben visibile benché protetta dalle palpebre. Non varia nel tempo ed è un tratto biometrico estremamente discriminante rispetto altri individui, ma anche all’interno dello stesso individuo. L’immagine può essere acquisita senza avere un contatto diretto (contactless). L’acquisizione dell’iride può avvenire in due modalità differenti: infrared e nel visibile. 
- *Svantaggi*: la superficie sulla quale bisogna poter effettuare l’estrazione delle caratteristiche è molto piccola, nella migliore delle ipotesi si parla di poco più di 3cm quadrati. Per poter acquisire l’iride, si dovrebbe disporre di dispositivi ad elevata risoluzione, che ovviamente dovrebbero adattarsi ad altre situazioni di contorno, ad esempio l’utente non dovrebbe indossare degli occhiali scuri.

L’iride come accennato può essere acquisita sia nel visibile che nell’infrarosso. La differenza sostanziale è legata alla quantità di melanina. Ovvero nel caso della luce visibile, la melanina assorbe la luce visibile, evidenziando gli strati che compongono l’iride sono visibili. L’immagine ottenuta con la luce visibile non permette di estrarre tutte le informazioni tridimensionali per una serie di problematiche. Nel caso della luce infrarossa, essa viene utilizzata nelle operazioni di verifica (utente altamente collaborativo), in questo caso la melanina riflette la maggior parte della luce infrarossa e assorbe la maggior parte della luce visibile, rendendo limitata la riflessione. La tessitura è più visibile e questo consente un elevato livello di sicurezza soprattutto nel contesto della verifica, appunto infatti si rende più adatta in sistemi biometrici basati sul riconoscimento dell’iride.

Uno dei problemi fondamentali dell’iride è la presenza di una serie di elementi che da un lato possono essere considerati perturbatori, e dall’altro elementi caratteristici della zona perioculare. In figura si possono evidenziare tutti gli elementi caratteristici della zona perioculare. Tutti questi elementi possono essere considerati parte di disturbo che possono essere combinate con un’altra serie di tipiche situazioni rumorose per l’acquisizione dell’iride come una scarsa illuminazione, o un’immagine con Blurring, un’occlusione oppure l’angolazione da cui viene effettuato lo scatto può essere sfavorevole per l’acquisizione. Tutte queste caratteristiche tendono a rendere difficile sia il processo di detection e sia il processo di estrazione delle caratteristiche. 

Normalmente un algoritmo per estrarre le caratteristiche dell’iride è caratterizzato da una serie di passi:

1. Segmentazione (o detection), quindi individuare che all’interno di un’immagine è presente un iride.

2. Normalizzazione.

3. Coding, che permette di estrarre le caratteristiche sulla base di un modello diversificato da caso a caso.

4. Matching, dove si confronta il codice prodotto nella fasi precedenti.

## Algoritmo di Daugman

Il primo algoritmo, completamente automatico, utilizzato per l’analisi dell’iride fu prodotto da Daugman. Esso propose la prima metodologia automatica basata su un algoritmo piuttosto efficiente di Iris Location (detection). Perché il problema fondamentale nell’iride è legato alla necessità di individuare un’iride all’interno di una immagine. La detection dell’iride risulta essere fondamentale. Il processo di estrazione delle feature è banale, una volta individuato l’iride l’estrazione delle caratteristiche è un problema secondario. Il problema principale come detto è riuscire ad individuare l’iride. Se non si inizia tale processo o lo si sbaglia, tutto ciò che viene dopo risulta essere fortemente compromesso. Daugman in un primo momento associò l’individuazione di un’iride all’individuazione di circonferenze che fossero in grado di determinare sia il cerchio della pupilla sia il cerchio più grande dell’iride. Quindi due cerchi concentrici tra di loro con lo stesso centro e raggio varabile. Esso immaginò di avere a disposizione un filtro gaussiano, fondamentale per la determina di tali cerchi, per evitare che le variazioni presenti all’interno dell’iride possano determinare dei False Alarms. 

Immaginò quindi un Edge Detector che producesse delle circonferenze a raggio variabile che andavano ad effettuare una convoluzione con un filtro gaussiano, quindi l’immagine veniva lisciata e veniva prodotta poi una circonferenza (edge detector circolare) che individuasse le transizioni più significative. Tale algoritmo si fermava quando si raggiungeva il cerchio a raggio massimo. Partendo dalla zona centrale (x0, y0) il primo cerchio che veniva prodotto a raggio massimo era quello che determina la transizione tra la pupilla e l’iride, e il secondo cerchio a raggio massimo che veniva prodotto era quello che determina la transizione tra l’iride e la sclera. Quindi effettuando la convoluzione tra il filtro gaussiano che effettua uno Smoothing dell’immagine ed evita la produzione di false Alarms e la generazione di cerchi a dimensione sempre maggiore, si determina questo operatore integro-differenziale che infine determina i candidati ideali a identificare l’iride. In figura si può osservare come opera l’algoritmo di Daugman. In maniera sequenziale a partire da un punto di un ipotetica iride inizia col generare una serie di cerchi che vanno a determinare le transizioni più elevate. 

Ogni volta questi cerchi vengono combinati con un algoritmo gaussiano che serve ad evitare variazioni non significative. I due cerchi con raggio massimo vengono poi etichettati per creare la corona circolare che determina l’area utile sulla quale andare ad effettuare l’estrazione delle caratteristiche. Ovviamente quest’area utile è solo parziale (in figura vi è un’immagine nel dominio infrared). Riassumendo si tratta di un banale filtro circolare come visto in precedenza, solo che esso lavora in simultanea con un filtro gaussiano onde evitare falsi allarmi nella zone dell’iride, tentando di arrivare fino alla transizione con la sclera in quanto essa rappresenta la variazione massima di transizione tra un’area e l’altra.

Una volta generato tale profilo, si etichettano i punti neri come punti appartenenti all’iride e i punti bianchi come punti non appartenenti all’iride. Si crea fondamentalmente una maschera che determina quali sono le aree sensibili. All’interno dell’iride ci possono essere dei puntini che vengono esclusi in quanto rappresentano zone di riflesso riducendo l’area dalla quale poter estrarre le caratteristiche. L’output della segmentazione, cioè dell’Iris Detection, è in realtà una maschera in bianco e nero.

Daugman nell’algoritmo aveva previsto una fase di normalizzazione, in quanto la dimensione dell’area significativa di un’iride era molto variabile. Essendo molto variabile poteva accadere di dover confrontare due iridi con dimensioni variabili dello spazio utile da cui estrarre le caratteristiche. Poiché l’iride, a differenza dell’impronta digitale, non presenta delle caratteristiche puntuali che vengono estratte ma che viene considerata nella sua intera superfice, vengono considerati tutti i pixel appartenenti alla superficie dell’iride. Si rese necessario che, dato l’intervento di elementi perturbatori, l’iride fosse normalizzato, proprio perché le aree utili erano diverse. Daugman applicò quindi vari algoritmi combinati tra loro che attraverso la combinazione tra coordinate polari e altri elementi di normalizzazione facessero in modo che tutte le superfici delle iridi estratte potessero avere sempre la stessa dimensione; creando così un vettore a dimensione fissa indipendentemente dall’area utile dell’iride estratta, proprio per non creare problemi nella fase di matching. 

Tra gli algoritmi di feature extraction più utilizzati, c’è una variante della trasformata di Fourier basata sui filtri di Gabor: si utilizzano dei filtri per catturare alcune informazioni significative dell’iride. Una volta individuata l’area di pertinenza, si tenta di estrarre da essa alcune informazioni aggregate. I filtri di Gabor sono una variante della trasformata di Fourier perché piuttosto che utilizzare la trasformata di Fourier del segnale, utilizzano la trasformata di Fourier combinata con la trasformata di Fourier di una gaussiana. In realtà il filtro era caratterizzato da una convoluzione tra la trasformata di Fourier e la trasformata di Fourier di una gaussiana. Quindi l’immagine viene proiettata nel dominio delle frequenze e non dei pixel. Infine, si avrà un vettore delle caratteristiche che banalmente viene identificato con i coefficienti di Gabor e su di essi viene effettuato un match attraverso la distanza di Hamming.